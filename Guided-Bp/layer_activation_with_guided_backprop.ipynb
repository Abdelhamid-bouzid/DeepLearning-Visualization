{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================== Library ============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import skimage.measure\n",
    "import pickle\n",
    "import numpy, scipy.io\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================== Functions ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    # Upload the data\n",
    "    return image_train, image_test, label_train, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1    = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv1_Bn = nn.BatchNorm2d(32)\n",
    "        self.relu_1     = nn.ReLU()\n",
    "        \n",
    "        self.conv2    = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_Bn = nn.BatchNorm2d(64)\n",
    "        self.relu_2     = nn.ReLU()\n",
    "        \n",
    "        self.conv3     = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.conv3_Bn  = nn.BatchNorm2d(64)\n",
    "        self.relu_3    = nn.ReLU()\n",
    "        \n",
    "        self.conv4     = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv4_Bn  = nn.BatchNorm2d(128)\n",
    "        self.relu_4    = nn.ReLU()\n",
    "        \n",
    "        self.conv5    = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.conv5_Bn = nn.BatchNorm2d(256)\n",
    "        self.relu_5   = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(2304,128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.conv1_Bn(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.conv2_Bn(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.conv3_Bn(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu_4(x)\n",
    "        x = self.conv4_Bn(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.relu_5(x)\n",
    "        x = self.conv5_Bn(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,2304)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(x,dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBackprop():\n",
    "    \"\"\"\n",
    "       Produces gradients generated with guided back propagation from the given image\n",
    "    \"\"\"\n",
    "    def __init__(self, model,):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        self.forward_relu_outputs = []\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "        self.update_relus()\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def update_relus(self):\n",
    "        \"\"\"\n",
    "            Updates relu activation functions so that\n",
    "                1- stores output in forward pass\n",
    "                2- imputes zero for gradient values that are less than zero\n",
    "        \"\"\"\n",
    "        def relu_backward_hook_function(module, grad_in, grad_out):\n",
    "            \"\"\"\n",
    "            If there is a negative gradient, change it to zero\n",
    "            \"\"\"\n",
    "            # Get last forward output\n",
    "            corresponding_forward_output = self.forward_relu_outputs[-1]\n",
    "            corresponding_forward_output[corresponding_forward_output > 0] = 1\n",
    "            modified_grad_out = corresponding_forward_output * torch.clamp(grad_in[0], min=0.0)\n",
    "            del self.forward_relu_outputs[-1]  # Remove last forward output\n",
    "            return (modified_grad_out,)\n",
    "\n",
    "        def relu_forward_hook_function(module, ten_in, ten_out):\n",
    "            \"\"\"\n",
    "            Store results of forward pass\n",
    "            \"\"\"\n",
    "            self.forward_relu_outputs.append(ten_out)\n",
    "\n",
    "        # Loop through layers, hook up ReLUs\n",
    "        for pos, module in model._modules.items():\n",
    "            if isinstance(module, torch.nn.modules.activation.ReLU):\n",
    "                print(pos)\n",
    "                module.register_backward_hook(relu_backward_hook_function)\n",
    "                module.register_forward_hook(relu_forward_hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class, cnn_layer, filter_pos):\n",
    "        \n",
    "        # Forward pass\n",
    "        x = input_image\n",
    "        for index, layer in self.model._modules.items():\n",
    "            x = layer(x)\n",
    "            if index == cnn_layer:\n",
    "                break\n",
    "                \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        conv_output = torch.sum(torch.abs(x[0, filter_pos]))\n",
    "        conv_output.backward()\n",
    "        \n",
    "        #convert to numpy\n",
    "        gradients   = self.gradients.cpu()\n",
    "        gradients_as_arr = gradients.data.numpy()[0]\n",
    "        return gradients_as_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_negative_saliency(gradient):\n",
    "    \"\"\"\n",
    "        Generates positive and negative saliency maps based on the gradient\n",
    "    Args:\n",
    "        gradient (numpy arr): Gradient of the operation to visualize\n",
    "    returns:\n",
    "        pos_saliency ( )\n",
    "    \"\"\"\n",
    "    pos_saliency = (np.maximum(0, gradient) / gradient.max())\n",
    "    neg_saliency = (np.maximum(0, -gradient) / -gradient.min())\n",
    "    \n",
    "    pos_saliency = np.moveaxis(pos_saliency,0,2)\n",
    "    neg_saliency = np.moveaxis(neg_saliency,0,2)\n",
    "    return pos_saliency, neg_saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================== upload model =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_Bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_1): ReLU()\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_Bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_2): ReLU()\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3_Bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_3): ReLU()\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4_Bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_4): ReLU()\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5_Bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_5): ReLU()\n",
       "  (fc1): Linear(in_features=2304, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model  = torch.load(r\"models\\model.pth\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================== Upload data ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train, image_test, label_train, label_test = read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = np.array(image_train).astype('float32')\n",
    "image_test  = np.array(image_test).astype('float32')\n",
    "\n",
    "image_train = np.moveaxis(image_train,-1,1)\n",
    "image_test  = np.moveaxis(image_test,-1,1)\n",
    "\n",
    "image_train = torch.from_numpy(image_train / 255.0)\n",
    "image_test  = torch.from_numpy(image_test / 255.0)\n",
    "label_train = torch.from_numpy(label_train)\n",
    "label_test  = torch.from_numpy(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==================== Plot original image ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 4500\n",
    "original_image = image_train[ind]\n",
    "target_class   = label_train[ind]\n",
    "plt.imshow(np.moveaxis(original_image.cpu().numpy(),0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================ Compute Gradient decent  ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu_1\n",
      "relu_2\n",
      "relu_3\n",
      "relu_4\n",
      "relu_5\n"
     ]
    }
   ],
   "source": [
    "im_as_ten  = original_image\n",
    "im_as_ten.unsqueeze_(0)\n",
    "prep_img   = Variable(im_as_ten, requires_grad=True).to(device)\n",
    "cnn_layer  = \"relu_2\"\n",
    "filter_pos = 1\n",
    "\n",
    "\n",
    "GBP = GuidedBackprop(model)\n",
    "guided_grads = GBP.generate_gradients(prep_img, target_class, cnn_layer, filter_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= Plot original saliency map ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_grads_1 = np.moveaxis(guided_grads,0,2)\n",
    "guided_grads_1 = (guided_grads_1 -guided_grads_1.min())/(guided_grads_1.max()-guided_grads_1.min())\n",
    "print(guided_grads_1.shape)\n",
    "plt.imshow(guided_grads_1)\n",
    "plt.imshow(np.expand_dims(np.sum(guided_grads_1,axis=2),axis=2)[...,0],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
