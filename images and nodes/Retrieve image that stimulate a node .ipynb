{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================== Library ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import skimage.measure\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "from pptx import Presentation\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pptx.enum.shapes import MSO_SHAPE\n",
    "from pptx.util import Inches, Pt,Cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================== Functions ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    # Upload the data \n",
    "    return image_train, image_test, label_train, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1      = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv1_Bn   = nn.BatchNorm2d(32)\n",
    "        self.relu_1     = nn.ReLU()\n",
    "        self.max_pool_1  = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2      = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_Bn   = nn.BatchNorm2d(64)\n",
    "        self.relu_2     = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.conv3      = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.conv3_Bn   = nn.BatchNorm2d(64)\n",
    "        self.relu_3     = nn.ReLU()\n",
    "        self.max_pool_3  = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4      = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv4_Bn   = nn.BatchNorm2d(128)\n",
    "        self.relu_4     = nn.ReLU()\n",
    "        self.max_pool_4  = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv5      = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.conv5_Bn   = nn.BatchNorm2d(256)\n",
    "        self.relu_5     = nn.ReLU()\n",
    "        \n",
    "        self.fc1        = nn.Linear(2304,128)\n",
    "        self.fc2        = nn.Linear(128,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.conv1_Bn(x)\n",
    "        x = self.max_pool_1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.conv2_Bn(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.conv3_Bn(x)\n",
    "        x = self.max_pool_3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu_4(x)\n",
    "        x = self.conv4_Bn(x)\n",
    "        x = self.max_pool_4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.relu_5(x)\n",
    "        x = self.conv5_Bn(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,2304)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(x,dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBackprop():\n",
    "    \"\"\"\n",
    "       Produces gradients generated with guided back propagation from the given image\n",
    "    \"\"\"\n",
    "    def __init__(self, model,):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        self.forward_relu_outputs = []\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "        self.update_relus()\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def update_relus(self):\n",
    "        \"\"\"\n",
    "            Updates relu activation functions so that\n",
    "                1- stores output in forward pass\n",
    "                2- imputes zero for gradient values that are less than zero\n",
    "        \"\"\"\n",
    "        def relu_backward_hook_function(module, grad_in, grad_out):\n",
    "            \"\"\"\n",
    "            If there is a negative gradient, change it to zero\n",
    "            \"\"\"\n",
    "            # Get last forward output\n",
    "            corresponding_forward_output = self.forward_relu_outputs[-1]\n",
    "            corresponding_forward_output[corresponding_forward_output > 0] = 1\n",
    "            modified_grad_out = corresponding_forward_output * torch.clamp(grad_in[0], min=0.0)\n",
    "            del self.forward_relu_outputs[-1]  # Remove last forward output\n",
    "            return (modified_grad_out,)\n",
    "\n",
    "        def relu_forward_hook_function(module, ten_in, ten_out):\n",
    "            \"\"\"\n",
    "            Store results of forward pass\n",
    "            \"\"\"\n",
    "            self.forward_relu_outputs.append(ten_out)\n",
    "\n",
    "        # Loop through layers, hook up ReLUs\n",
    "        for pos, module in model._modules.items():\n",
    "            if isinstance(module, torch.nn.modules.activation.ReLU):\n",
    "                print(pos)\n",
    "                module.register_backward_hook(relu_backward_hook_function)\n",
    "                module.register_forward_hook(relu_forward_hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class, cnn_layer, filter_pos):\n",
    "        \n",
    "        # Forward pass\n",
    "        x = input_image\n",
    "        for index, layer in self.model._modules.items():\n",
    "            x = layer(x)\n",
    "            if index == cnn_layer:\n",
    "                break\n",
    "                \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        conv_output = torch.sum(torch.abs(x[0, filter_pos]))\n",
    "        conv_output.backward()\n",
    "        \n",
    "        #convert to numpy\n",
    "        gradients   = self.gradients.cpu()\n",
    "        gradients_as_arr = gradients.data.numpy()[0]\n",
    "        return gradients_as_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_negative_saliency(gradient):\n",
    "    \"\"\"\n",
    "        Generates positive and negative saliency maps based on the gradient\n",
    "    Args:\n",
    "        gradient (numpy arr): Gradient of the operation to visualize\n",
    "    returns:\n",
    "        pos_saliency ( )\n",
    "    \"\"\"\n",
    "    pos_saliency = (np.maximum(0, gradient) / gradient.max())\n",
    "    neg_saliency = (np.maximum(0, -gradient) / -gradient.min())\n",
    "    \n",
    "    pos_saliency = np.moveaxis(pos_saliency,0,2)\n",
    "    neg_saliency = np.moveaxis(neg_saliency,0,2)\n",
    "    return pos_saliency, neg_saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_gpu(s,e,flag):\n",
    "    if flag==0:\n",
    "        image = image_train[s:e].to(device)\n",
    "        label = label_train[s:e].to(device)\n",
    "    else:\n",
    "        image  = image_test[s:e].to(device)\n",
    "        label  = label_test[s:e].to(device)    \n",
    "    \n",
    "    return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_images(images,cnn_layer):\n",
    "    batchsize  = 50\n",
    "    images_out = []\n",
    "    l = [(x,x+batchsize) for x in range(0,images.shape[0],batchsize)]\n",
    "    for s,e in l:\n",
    "        image_train1, label_train1 = move_to_gpu(s,e,0)\n",
    "        for index, layer in model._modules.items():\n",
    "            image_train1 = layer(image_train1)\n",
    "            if index == cnn_layer:\n",
    "                break\n",
    "        image_train1 = image_train1.cpu().data.numpy()\n",
    "        images_out.append(image_train1)\n",
    "    images_out = np.concatenate(images_out,axis=0)\n",
    "    images_out = np.moveaxis(images_out,1,-1)\n",
    "    return images_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesdef Node_Best_images(images_out,percentile):\n",
    "    \n",
    "    outputs    = images_out.reshape((images_out.shape[0],images_out.shape[1]*images_out.shape[2],images_out.shape[3]))\n",
    "    mat_1      = np.zeros((outputs.shape[0],outputs.shape[2]))\n",
    "    for i in range(outputs.shape[2]):\n",
    "        mat        = outputs[:,:,i]\n",
    "        ind        = int(round(percentile*outputs.shape[1]))\n",
    "        a          = -1*np.sort(-mat,axis=1)\n",
    "        b          = a[:,:ind]\n",
    "        c          = np.mean(b,axis=1)\n",
    "        mat_1[:,i] = c\n",
    "            \n",
    "    filter_images = np.argsort(-mat_1,axis=0)\n",
    "    mat_2         = -1*np.sort(-mat_1,axis=0)\n",
    "    mat_3         = np.mean(mat_2[:9,:],axis=0)\n",
    "    mat_4         = np.argsort(-mat_3)\n",
    "    return filter_images,mat_1,mat_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(filters_list,images,images_out,ss):\n",
    "    \n",
    "    fig     = plt.figure(figsize=(10, 20))\n",
    "    columns = 2\n",
    "    rows    = len(filters_list)\n",
    "    m       = 1\n",
    "    for k in filters_list:\n",
    "        \n",
    "        inds = filter_images[:9,k]\n",
    "        \n",
    "        rw_size    = 64\n",
    "        cl_size    = 64\n",
    "        margin     = 5\n",
    "        results_1  = np.zeros((3 * rw_size + 2 * margin, 3 * cl_size + 2 * margin,1))\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):    \n",
    "\n",
    "                #filter_img       = images_out[inds[j + (i * 3)],:,:,k]\n",
    "                im_as_ten        = images[inds[j + (i * 3)],:,:,:]\n",
    "                im_as_ten.unsqueeze_(0)\n",
    "                prep_img         = Variable(im_as_ten, requires_grad=True).to(device)\n",
    "                target_class     = label_train[j + (i * 3)]\n",
    "                guided_grads     = GBP.generate_gradients(prep_img, target_class, cnn_layer, k)\n",
    "                guided_grads_1   = np.moveaxis(guided_grads,0,2)\n",
    "                guided_grads_1   = (guided_grads_1 -guided_grads_1.min())/(guided_grads_1.max()-guided_grads_1.min())\n",
    "                guided_grads_1   = np.expand_dims(np.sum(guided_grads_1,axis=2),axis=2)\n",
    "                \n",
    "                horizontal_start = i * rw_size + i * margin\n",
    "                horizontal_end   = horizontal_start + rw_size\n",
    "                vertical_start   = j * cl_size + j * margin\n",
    "                vertical_end     = vertical_start + cl_size\n",
    "\n",
    "                results_1[horizontal_start: horizontal_end, vertical_start: vertical_end,:] = guided_grads_1\n",
    "        \n",
    "        fig.add_subplot(rows, columns, m)\n",
    "        fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "        plt.imshow(results_1[...,0],cmap=\"gray\")\n",
    "        s = \"Node: \"+str(k)+\" outputs\"+\"\\n\"+np.array2string(label_train[inds].numpy(), precision=0, separator=',',suppress_small=True)+\"\\n\"+np.array2string(response[inds,k], precision=2, separator=',',suppress_small=True)\n",
    "        plt.title(s)\n",
    "        m = m+1\n",
    "        \n",
    "        rw_size    = 64\n",
    "        cl_size    = 64\n",
    "        margin     = 5\n",
    "        results_2  = np.zeros((3 * rw_size + 2 * margin, 3 * cl_size + 2 * margin,3))\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                \n",
    "                filter_img       = images[inds[j + (i * 3)],:,:,:].numpy()\n",
    "                filter_img       = np.moveaxis(filter_img,0,-1)\n",
    "                \n",
    "                horizontal_start = i * rw_size + i * margin\n",
    "                horizontal_end   = horizontal_start + rw_size\n",
    "                vertical_start   = j * cl_size + j * margin\n",
    "                vertical_end     = vertical_start + cl_size\n",
    "\n",
    "                results_2[horizontal_start: horizontal_end, vertical_start: vertical_end,:] = filter_img\n",
    "                \n",
    "        fig.add_subplot(rows, columns, m)\n",
    "        fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "        plt.imshow(results_2)\n",
    "        s = \"Node: \"+str(k)+\" outputs\"+\"\\n\"+np.array2string(label_train[inds].numpy(), precision=0, separator=',',suppress_small=True)+\"\\n\"+np.array2string(response[inds,k], precision=2, separator=',',suppress_small=True)\n",
    "        plt.title(s)\n",
    "        m = m+1\n",
    "    plt.savefig(ss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenSlide(Slide,Title,Path_1,Path_2,Path_3):\n",
    "    title_placeholder      = slide.shapes.title\n",
    "    title_placeholder.text = Title\n",
    "    shapes                 = slide.shapes\n",
    "    \n",
    "    picture_1 = shapes.add_picture(Path_1,Cm(1),Cm(0))\n",
    "    \n",
    "    picture_1.crop_left   = 0.035\n",
    "    picture_1.crop_right  = 0.09\n",
    "    picture_1.crop_top    = 0.055\n",
    "    picture_1.crop_bottom = 0.01\n",
    "\n",
    "    picture_1.height = Cm(18)\n",
    "    picture_1.width  = Cm(8)\n",
    "    \n",
    "    picture_2= shapes.add_picture(Path_2,Cm(9),Cm(0))\n",
    "    \n",
    "    picture_2.crop_left   = 0.035\n",
    "    picture_2.crop_right  = 0.09\n",
    "    picture_2.crop_top    = 0.055\n",
    "    picture_2.crop_bottom = 0.01\n",
    "    \n",
    "    picture_2.height = Cm(18)\n",
    "    picture_2.width  = Cm(8)\n",
    "    \n",
    "    picture_3= shapes.add_picture(Path_3,Cm(17),Cm(0))\n",
    "    \n",
    "    picture_3.crop_left   = 0.035\n",
    "    picture_3.crop_right  = 0.09\n",
    "    picture_3.crop_top    = 0.055\n",
    "    picture_3.crop_bottom = 0.01\n",
    "    \n",
    "    picture_3.height = Cm(18)\n",
    "    picture_3.width  = Cm(8)\n",
    "    \n",
    "    return Slide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================== upload model =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 62, 62]             896\n",
      "              ReLU-2           [-1, 32, 62, 62]               0\n",
      "       BatchNorm2d-3           [-1, 32, 62, 62]              64\n",
      "         MaxPool2d-4           [-1, 32, 31, 31]               0\n",
      "            Conv2d-5           [-1, 64, 29, 29]          18,496\n",
      "              ReLU-6           [-1, 64, 29, 29]               0\n",
      "       BatchNorm2d-7           [-1, 64, 29, 29]             128\n",
      "            Conv2d-8           [-1, 64, 27, 27]          36,928\n",
      "              ReLU-9           [-1, 64, 27, 27]               0\n",
      "      BatchNorm2d-10           [-1, 64, 27, 27]             128\n",
      "        MaxPool2d-11           [-1, 64, 13, 13]               0\n",
      "           Conv2d-12          [-1, 128, 11, 11]          73,856\n",
      "             ReLU-13          [-1, 128, 11, 11]               0\n",
      "      BatchNorm2d-14          [-1, 128, 11, 11]             256\n",
      "        MaxPool2d-15            [-1, 128, 5, 5]               0\n",
      "           Conv2d-16            [-1, 256, 3, 3]         295,168\n",
      "             ReLU-17            [-1, 256, 3, 3]               0\n",
      "      BatchNorm2d-18            [-1, 256, 3, 3]             512\n",
      "           Linear-19                  [-1, 128]         295,040\n",
      "           Linear-20                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 722,762\n",
      "Trainable params: 722,762\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 5.87\n",
      "Params size (MB): 2.76\n",
      "Estimated Total Size (MB): 8.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = torch.load(r\"models\\model.pth\").to(device)\n",
    "model.eval()\n",
    "summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================== Upload data ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train, image_test, label_train, label_test = read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = np.array(image_train).astype('float32')\n",
    "image_test  = np.array(image_test).astype('float32')\n",
    "\n",
    "image_train = np.moveaxis(image_train,-1,1)\n",
    "image_test  = np.moveaxis(image_test,-1,1)\n",
    "\n",
    "image_train = torch.from_numpy(image_train / 255.0)\n",
    "image_test  = torch.from_numpy(image_test / 255.0)\n",
    "label_train = torch.from_numpy(label_train)\n",
    "label_test  = torch.from_numpy(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layer  = \"relu_4\"\n",
    "images_out = forward_images(image_train,cnn_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_images,response,node_order = Node_Best_images(images_out,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================ Display in presentation ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLD_SECTION                  = 0\n",
    "SLD_LAYOUT_TITLE_AND_CONTENT = 1\n",
    "prs                          = Presentation()\n",
    "slide_layout                 = prs.slide_layouts[SLD_SECTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu_1\n",
      "relu_2\n",
      "relu_3\n",
      "relu_4\n",
      "relu_5\n"
     ]
    }
   ],
   "source": [
    "GBP = GuidedBackprop(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [x for x in range(0,filter_images.shape[1],3)]\n",
    "for i, x in enumerate(l):\n",
    "    s = str(i%3)+\".jpg\"\n",
    "    \n",
    "    if x == 126:\n",
    "            filters_list = [node_order[126],node_order[127]]\n",
    "    else:\n",
    "        filters_list = [node_order[x],node_order[x+1],node_order[x+2]]\n",
    "        \n",
    "    display(filters_list,image_train,images_out,s)\n",
    "    \n",
    "    if i%3==2:\n",
    "        \n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        Slide = GenSlide(slide,\"Title\",\"0.jpg\",\"1.jpg\",\"2.jpg\")\n",
    "prs.save(r'prsentation\\presentation80.pptx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
